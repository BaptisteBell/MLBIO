{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Federate Learing Implementation"
      ],
      "metadata": {
        "id": "sAF4Zb89epvE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Load the MNIST dataset (or any other dataset like HAM 10000)"
      ],
      "metadata": {
        "id": "l0_SFSKQeuRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = '/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doikC4tIwfWr",
        "outputId": "6b9080bf-44be-4b48-e65c-88da0c814ddf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmd5bXp5gzx5",
        "outputId": "16b59402-6b89-4aab-e7c2-54f4c63fea68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training samples: 60000\n",
            "Test samples: 10000\n",
            "Image shape: (28, 28)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "#Normalized\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "print(\"Training samples:\", x_train.shape[0])\n",
        "print(\"Test samples:\", x_test.shape[0])\n",
        "print(\"Image shape:\", x_train.shape[1:])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Extract two subsets of 600 data points each (without intersection)"
      ],
      "metadata": {
        "id": "Fq7eDNtHeyVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def create_client_datasets(x_train, y_train, subset_size, printed=False):\n",
        "  indices = np.arange(x_train.shape[0])\n",
        "  np.random.shuffle(indices)\n",
        "\n",
        "  subset1_indices = indices[:subset_size]\n",
        "  subset2_indices = indices[subset_size:subset_size*2]\n",
        "\n",
        "  subset1_x = x_train[subset1_indices]\n",
        "  subset1_y = y_train[subset1_indices]\n",
        "\n",
        "  subset2_x = x_train[subset2_indices]\n",
        "  subset2_y = y_train[subset2_indices]\n",
        "\n",
        "  subset1_x = subset1_x[..., np.newaxis]\n",
        "  subset2_x = subset2_x[..., np.newaxis]\n",
        "\n",
        "  if (printed):\n",
        "    print(\"Subset 1 X shape:\", subset1_x.shape)\n",
        "    print(\"Subset 1 Y shape:\", subset1_y.shape)\n",
        "    print(\"Subset 2 X shape:\", subset2_x.shape)\n",
        "    print(\"Subset 2 Y shape:\", subset2_y.shape)\n",
        "\n",
        "\n",
        "  client_datasets = [\n",
        "      (subset1_x, subset1_y),\n",
        "      (subset2_x, subset2_y)\n",
        "  ]\n",
        "\n",
        "  return client_datasets\n",
        "\n",
        "client_datasets = create_client_datasets(x_train, y_train, 600, printed=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLTMcL4XkKxo",
        "outputId": "edc65e50-4a22-408f-ac50-540466c04b9f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset 1 X shape: (600, 28, 28, 1)\n",
            "Subset 1 Y shape: (600,)\n",
            "Subset 2 X shape: (600, 28, 28, 1)\n",
            "Subset 2 Y shape: (600,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Create a simple Convolutional Neural Network (2 convolutional layers and 2 dense layers, for example)"
      ],
      "metadata": {
        "id": "miHl-phAe1f7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "def create_model():\n",
        "  model = Sequential([\n",
        "      Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "      MaxPooling2D((2, 2)),\n",
        "      Conv2D(64, (3, 3), activation='relu'),\n",
        "      MaxPooling2D((2, 2)),\n",
        "      Flatten(),\n",
        "      Dense(128, activation='relu'),\n",
        "      Dense(10, activation='softmax')  # 10 classes for MNIST digits\n",
        "  ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "VHf649PDsHF8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Create a function average_model_parameters(models: iterable, average_weight): iterable that takes a list of models as an argument and returns the weighted average of the parameters of each model."
      ],
      "metadata": {
        "id": "82iPI1_Ae5Ep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections.abc import Iterable\n",
        "\n",
        "def average_model_parameters(models: Iterable, average_weight: list):\n",
        "    model_params = [list(model.get_weights()) for model in models]\n",
        "\n",
        "    averaged_params = []\n",
        "    for params in zip(*model_params):\n",
        "        weighted_sum = sum(weight * param for weight, param in zip(average_weight, params))\n",
        "        averaged_params.append(weighted_sum)\n",
        "\n",
        "    return averaged_params\n"
      ],
      "metadata": {
        "id": "DrMMVdePsZQ7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.Create a function that updates the parameters of a model from a list of values"
      ],
      "metadata": {
        "id": "Z9M91YKae8ZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_model_parameters(model, new_weights):\n",
        "    model.set_weights(new_weights)\n"
      ],
      "metadata": {
        "id": "6AWRe5LytGOl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.Create a script/code/function that reproduces Algorithm 1, considering that both models are on your machine. Use an average_weight=[1/2, 1/2]. Reuse the same setup as in the article (50 examples per local batch)"
      ],
      "metadata": {
        "id": "RB_6US48e_J1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import clone_model\n",
        "import tensorflow as tf\n",
        "\n",
        "def federated_averaging(global_model, client_datasets, num_clients, rounds, epochs, batch_size, learning_rate, loss = 'sparse_categorical_crossentropy', common_parameter=True, fraction_clients=0.5, average_weight=[0.5,0.5]):\n",
        "    for t in range(rounds):\n",
        "        print(f\"Round {t + 1}/{rounds}\")\n",
        "\n",
        "        m = max(int(fraction_clients * num_clients), 1)\n",
        "        selected_clients = np.random.choice(num_clients, m, replace=False)\n",
        "\n",
        "        client_models = []\n",
        "\n",
        "        for client_idx in selected_clients:\n",
        "            x_client, y_client = client_datasets[client_idx]\n",
        "\n",
        "            with tf.device(device):\n",
        "              if common_parameter:\n",
        "                local_model = clone_model(global_model)\n",
        "                local_model.set_weights(global_model.get_weights())\n",
        "              else:\n",
        "                local_model = create_model()\n",
        "              local_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
        "                                  loss=loss,\n",
        "                                  metrics=['accuracy'])\n",
        "              local_model.fit(x_client, y_client, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "              client_models.append(local_model)\n",
        "\n",
        "        weights = [len(client_datasets[client_idx][0]) for client_idx in selected_clients]\n",
        "        average_weight = [weight / sum(weights) for weight in weights]\n",
        "        averaged_weights = average_model_parameters(client_models, average_weight)\n",
        "\n",
        "        global_model.set_weights(averaged_weights)\n",
        "\n",
        "    return global_model\n"
      ],
      "metadata": {
        "id": "Utty4CXewSQB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.Train your models without initializing the common parameters and measure the performance on the entire dataset."
      ],
      "metadata": {
        "id": "PkCVWD0Afb7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#No initialization\n",
        "global_model = create_model()\n",
        "\n",
        "federated_model = federated_averaging(\n",
        "    global_model=global_model,\n",
        "    client_datasets=client_datasets,\n",
        "    num_clients=2,\n",
        "    rounds=10,\n",
        "    epochs=10,\n",
        "    batch_size=50,\n",
        "    learning_rate=0.01,\n",
        "    fraction_clients=1.0,\n",
        "    common_parameter=False\n",
        ")\n",
        "\n",
        "federated_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "loss_global, acc_global = federated_model.evaluate(x_test[..., np.newaxis], y_test, verbose=0)\n",
        "\n",
        "print(f\"Global Model Accuracy: {acc_global:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpY0a20HcgP8",
        "outputId": "b6cedb66-2cd9-444f-ebae-f1fe4aeea0f6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1/10\n",
            "Round 2/10\n",
            "Round 3/10\n",
            "Round 4/10\n",
            "Round 5/10\n",
            "Round 6/10\n",
            "Round 7/10\n",
            "Round 8/10\n",
            "Round 9/10\n",
            "Round 10/10\n",
            "Global Model Accuracy: 0.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.Train your models with the initialization of common parameters and verify that the performance is better."
      ],
      "metadata": {
        "id": "qS9ABimvffKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initialization\n",
        "global_model = create_model()\n",
        "\n",
        "federated_model = federated_averaging(\n",
        "    global_model=global_model,\n",
        "    client_datasets=client_datasets,\n",
        "    num_clients=2,\n",
        "    rounds=10,\n",
        "    epochs=10,\n",
        "    batch_size=50,\n",
        "    learning_rate=0.01,\n",
        "    fraction_clients=1.0\n",
        ")\n",
        "\n",
        "federated_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "loss_global, acc_global = federated_model.evaluate(x_test[..., np.newaxis], y_test, verbose=0)\n",
        "\n",
        "print(f\"Global Model Accuracy: {acc_global:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKsHjQQeCTBL",
        "outputId": "33a82ae9-fd67-4231-e488-bf676b5e1905"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1/10\n",
            "Round 2/10\n",
            "Round 3/10\n",
            "Round 4/10\n",
            "Round 5/10\n",
            "Round 6/10\n",
            "Round 7/10\n",
            "Round 8/10\n",
            "Round 9/10\n",
            "Round 10/10\n",
            "Global Model Accuracy: 0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that when the models are initialized with the same parameters (from global model), the final results are better."
      ],
      "metadata": {
        "id": "q7h3ff9Z3WDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.Reduce the number of data points in each sub-batch. What is the minimum number of data points necessary for the final model to have acceptable performance? Repeat the study on CIFAR-10"
      ],
      "metadata": {
        "id": "ahZ5vK7LfttN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client_datasets_50 = create_client_datasets(x_train, y_train, 50)\n",
        "client_datasets_100 = create_client_datasets(x_train, y_train, 100)\n",
        "client_datasets_150 = create_client_datasets(x_train, y_train, 150)\n",
        "client_datasets_200 = create_client_datasets(x_train, y_train, 200)\n",
        "\n",
        "all_clients_datasets = [client_datasets_50, client_datasets_100, client_datasets_150, client_datasets_200]\n",
        "results = []\n",
        "\n",
        "for i in range(len(all_clients_datasets)):\n",
        "  cl_datasets = all_clients_datasets[i]\n",
        "  global_model = create_model()\n",
        "\n",
        "  federated_model = federated_averaging(\n",
        "      global_model=global_model,\n",
        "      client_datasets=cl_datasets,\n",
        "      num_clients=2,\n",
        "      rounds=7,\n",
        "      epochs=10,\n",
        "      batch_size=50,\n",
        "      learning_rate=0.01,\n",
        "      fraction_clients=1.0\n",
        "  )\n",
        "\n",
        "  federated_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  loss_global, acc_global = federated_model.evaluate(x_test[..., np.newaxis], y_test, verbose=0)\n",
        "  results.append({'datasets_size': 50*(i+1),'loss': loss_global, 'accuracy': acc_global})\n",
        "\n",
        "for result in results:\n",
        "  print(result)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXfm6aONGHiC",
        "outputId": "2a3f8ad6-64bb-4d7d-be1a-19bb0c8f4f1f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1/7\n",
            "Round 2/7\n",
            "Round 3/7\n",
            "Round 4/7\n",
            "Round 5/7\n",
            "Round 6/7\n",
            "Round 7/7\n",
            "Round 1/7\n",
            "Round 2/7\n",
            "Round 3/7\n",
            "Round 4/7\n",
            "Round 5/7\n",
            "Round 6/7\n",
            "Round 7/7\n",
            "Round 1/7\n",
            "Round 2/7\n",
            "Round 3/7\n",
            "Round 4/7\n",
            "Round 5/7\n",
            "Round 6/7\n",
            "Round 7/7\n",
            "Round 1/7\n",
            "Round 2/7\n",
            "Round 3/7\n",
            "Round 4/7\n",
            "Round 5/7\n",
            "Round 6/7\n",
            "Round 7/7\n",
            "{'datasets_size': 50, 'loss': 2.224083185195923, 'accuracy': 0.21629999577999115}\n",
            "{'datasets_size': 100, 'loss': 1.7315049171447754, 'accuracy': 0.4867999851703644}\n",
            "{'datasets_size': 150, 'loss': 0.9667416214942932, 'accuracy': 0.7534999847412109}\n",
            "{'datasets_size': 200, 'loss': 0.6597244143486023, 'accuracy': 0.7983999848365784}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minimum minimum number of data points necessary for the final model to have acceptable performance is 150"
      ],
      "metadata": {
        "id": "WI-lu2LalQ2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CYFAR-10 test"
      ],
      "metadata": {
        "id": "BxybrnQHGsD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(x_train_cyphar, y_train_cyphar), (x_test_cyphar, y_test_cyphar) = cifar10.load_data()\n",
        "\n",
        "x_train_cyphar = x_train_cyphar.astype('float32') / 255.0\n",
        "x_test_cyphar = x_test_cyphar.astype('float32') / 255.0\n",
        "\n",
        "y_train_cyphar = to_categorical(y_train_cyphar, 10)\n",
        "y_test_cyphar = to_categorical(y_test_cyphar, 10)\n",
        "\n",
        "print(\"Training samples:\", x_train_cyphar.shape[0])\n",
        "print(\"Test samples:\", x_test_cyphar.shape[0])\n",
        "print(\"Image shape:\", x_train_cyphar.shape[1:])\n"
      ],
      "metadata": {
        "id": "Y62L7z3QGrt5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72d5060f-f51a-4cd3-bca0-a06d1f5c14eb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Training samples: 50000\n",
            "Test samples: 10000\n",
            "Image shape: (32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  model = Sequential([\n",
        "      Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "      MaxPooling2D((2, 2)),\n",
        "      Conv2D(64, (3, 3), activation='relu'),\n",
        "      MaxPooling2D((2, 2)),\n",
        "      Flatten(),\n",
        "      Dense(128, activation='relu'),\n",
        "      Dense(10, activation='softmax')  # 10 classes for MNIST digits\n",
        "  ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "P8mJhTxPpUCP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client_datasets_cyphar_1500 = create_client_datasets(x_train_cyphar, y_train_cyphar, 1500)\n",
        "client_datasets_cyphar_1750 = create_client_datasets(x_train_cyphar, y_train_cyphar, 1750)\n",
        "client_datasets_cyphar_2000 = create_client_datasets(x_train_cyphar, y_train_cyphar, 2000)\n",
        "\n",
        "all_clients_datasets_cyphar = [client_datasets_cyphar_1500, client_datasets_cyphar_1750, client_datasets_cyphar_2000]\n",
        "sizes = [600, 1000, 1500]\n",
        "\n",
        "results_cyphar = []\n",
        "for i in range(len(all_clients_datasets_cyphar)):\n",
        "  cl_datasets_cyphar = all_clients_datasets_cyphar[i]\n",
        "  size = sizes[i]\n",
        "  global_model = create_model()\n",
        "  federated_model = federated_averaging(\n",
        "      global_model=global_model,\n",
        "      client_datasets=cl_datasets_cyphar,\n",
        "      num_clients=2,\n",
        "      rounds=7,\n",
        "      epochs=10,\n",
        "      batch_size=50,\n",
        "      learning_rate=0.01,\n",
        "      fraction_clients=1.0,\n",
        "      loss = 'categorical_crossentropy'\n",
        "  )\n",
        "\n",
        "  federated_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  loss_global, acc_global = federated_model.evaluate(x_test_cyphar[..., np.newaxis], y_test_cyphar, verbose=0)\n",
        "\n",
        "  results_cyphar.append({'datasets_size': size, 'loss': loss_global, 'accuracy': acc_global})\n",
        "\n",
        "for result in results_cyphar:\n",
        "  print(result)"
      ],
      "metadata": {
        "id": "DGWrFypjHNhr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e48f355d-59bf-4e6c-fd9d-afb1ee93c80c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1/7\n",
            "Round 2/7\n",
            "Round 3/7\n",
            "Round 4/7\n",
            "Round 5/7\n",
            "Round 6/7\n",
            "Round 7/7\n",
            "Round 1/7\n",
            "Round 2/7\n",
            "Round 3/7\n",
            "Round 4/7\n",
            "Round 5/7\n",
            "Round 6/7\n",
            "Round 7/7\n",
            "Round 1/7\n",
            "Round 2/7\n",
            "Round 3/7\n",
            "Round 4/7\n",
            "Round 5/7\n",
            "Round 6/7\n",
            "Round 7/7\n",
            "{'datasets_size': 600, 'loss': 1.6058480739593506, 'accuracy': 0.4316999912261963}\n",
            "{'datasets_size': 1000, 'loss': 1.5184733867645264, 'accuracy': 0.45820000767707825}\n",
            "{'datasets_size': 1500, 'loss': 1.5298556089401245, 'accuracy': 0.46369999647140503}\n"
          ]
        }
      ]
    }
  ]
}